# Case-study оптимизации

## Актуальная проблема

В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики

Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: запуск rake-задачи с функцией `time`

```bash
time be rake reload_json\[fixtures/small.json\]
bundle exec rake reload_json\[fixtures/small.json\]  5.44s user 0.39s system 79% cpu 7.377 total
```

## Гарантия корректности работы оптимизированной программы

Для корректности работы был предоставлен пример результатов, которые должны получиться и с ними происходила сверка.

## Feedback-Loop

Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за, вначале, ~7s.

Вот как я построил `feedback_loop`: запуск

## Вникаем в детали системы, чтобы найти главные точки роста

Для того, чтобы найти "точки роста" для оптимизации я воспользовался: `rack-mini-profiler`, `rails panel`, `bullet`, `activerecord-import`.

Вот какие проблемы удалось найти и решить

- В rake-задаче я решил, что все должно выполняться батчами и не лезть лишний раз в базу с `SELECT`-ами.

```bash
time be rake reload_json\[fixtures/example.json\]
=== before [example.json] ===
0.43s user 0.15s system 68% cpu 0.843 total

=== after [example.json] ===
0.38s user 0.14s system 69% cpu 0.755 total

time be rake reload_json\[fixtures/small.json\]
=== before [small.json] ===
5.57s user 0.42s system 74% cpu 8.032 total

=== after [small.json] ===
0.43s user 0.14s system 67% cpu 0.853 total

time be rake reload_json\[fixtures/medium.json\]
=== before [medium.json] ===
40.15s user 2.23s system 77% cpu 54.928 total

=== after [medium.json] ===
0.87s user 0.15s system 74% cpu 1.373 total

time be rake reload_json\[fixtures/large.json\]
=== after [large.json] ===
2.46s user 0.23s system 62% cpu 4.313 total

time be rake reload_json\[fixtures/1M.json\]
=== after [1M.json] ===
24.88s user 1.63s system 63% cpu 41.543 total
```

- Для оптимизации `SELECT`-ов внутри уже работающего приложения я увидел частые обращения через внешние ключи, поэтому накинул на них B-индексы.

- Такие же индексы я добавил на поля, через которые идут частые `SELECT`-ы.

- Для оптимизации SSR страницы Rails, с помощью `bullet` я заметил, что присутствует ряд N+1 запросов, поэтому добавил `includes` для прелоада информации из базы.

- С помощью `rack-mini-profiler` обнаружил, что большое количество паршалов рендерятся очень медленно, поэтому слил их в один паршал `_trip.html.erb` и отрендерил их коллекцией.

## Результаты

В результате проделанной оптимизации наконец удалось обработать файл с данными.

- Удалось улучшить метрику загрузки дампа с `~54s` до `~1.4s` для файла `medium.json` и уложиться в заданный бюджет.
- Страница `/автобусы/Самара/Москва` для дампа из файла `large.json` грузится со скоростью:

  - по информации `rack-mini-profiler` ~1328ms
  - по информации Rails консоли ~772ms

## Тесты

- Были написаны тесты функциональности
- К сожалению, не получилось применить тесты производительности к Rake задаче. Они словно показывают время самого вызова функции, как результат это микросекунды (11 μs).
