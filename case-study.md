# Case-study

## Актуальная проблема
В проекте используется импорт расписаний из `json` файла.
Импорт отрабатывал в пределах минуты, пока файл имел до 10k импортируемых записей. С увеличением объема данных импорт данных стал выполняться слишком долго.
При первом рассмотрении, стало понятно что загрузка данных из файла производится неэффективно.
Кроме того, с увеличением количества записей, страница расписаний автобусов загружается слишком медленно.

Мною принято решение:
 - исправить и оптимизировать код reke-задачи, которая отвечает за импорт
 - найти и устранить проблемы, замедляющие формирование ответа сервера для страниц расписаний

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я решил использовать такую метрику: *время обработки файла с 1000 тыс. записей*

## Гарантия корректности работы оптимизированной программы
Наше Rails приложение не имело тестов. Для гарантии корректности внесенных изменений я добавил 2 теста, первый отвечает за корректность импорта, второй отвечает за корректность вывода данных на странице рассписаний автобусов. Выполнение  теста на корректность импорта в фидбэк лупе позволяет не допустить изменения логики работы импорта, а тест на контроллер позволяет не допустить изменения в отображении контента при оптимизации контроллера.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *10 секунд*


Вот как я построил `feedback_loop`:
  - для импорта
    * измеряю время работы импорта и на callstack отчете определяю медленное место
    * смотрю отчеты `pghero` на наличие медленных или часто повторяющихся запросов
    * изменяю код, сохраняю файл
    * жду прохождения автотеста и получения отчета времени работы `bm realtime`
    * с помощью фреймворка оптимизации запускаю дополнительные профилировщики

  - для страницы `автобусы/Самара/Москва`
    * смотрю отчеты `pghero` и `rack-mini-profiler`
    * оптимизирую
    * сравниваю тайминг загрузки и количество и длительность запросов к базе с предыдущей итерацией
    * запускаю тест на кортроллер и контент страницы
## Вникаем в детали системы, чтобы найти главные точки роста
### Подготовка
До начала работ с импортом я провел ревизию фреймворка оптимизации, добавил необходимые исполняемые файлы в папку  `app/script/benchmarks` согласно соглашению о конфигурации Rails. Так-же добавил необходимые хелпер-методы в `benchmark_helper.rb`.

Для того, чтобы найти "точки роста" для оптимизации я разнес код по отдельным методам `flush_db`, `fetch_from`, `fetch_to`, `fetch_services`, `fetch_bus`, `update_bus` - это помогло добавить информативности отчетам профилировщиков.

Затем я воспользовался инструментами:
  - *benchmark realtime* показал, что файл с `small.json` скрипт обрабатывает ~6 сек, а 10,000 ~60 сек. Можно предположить, что асимптотика линейная
  - *stackprof wall & speedscope.app* показал, что половину всего времени (~3 сек на файле с `small.json`) занимает работа с базой во главе с PostgreSQLAdapter
  - *ruby_prof graph* показал 6788 обращений к методу #transaction
  - *ruby_prof walltime callstack* показал наибольшее время выполнения методов #update_bus и #fetch_services
  - *memory_profiler*
  - *pghero* после активации расширения и загрузки `medium.json` показал самый долгий запрос `SELECT "services".* FROM "services" INNER JOIN "buses_services" ON "services"."id" = "buses_services"."service_id" WHERE "buses_services"."bus_id" = $1`
  - *pg_query*
  - *strong_migrations*
  - *activerecord-import*
  - *rack-mini-profiler*

## Импорт

###  Находка №1
- большое количество транзакций
- добавил кэширование Service и City, убрал `Bus#update`, задействовал гем `activerecord-import`: сделал импорт автобусов и поездок, а так-же обновление join-таблицы `buses_services` в батчах по 1000
- количество транзакций снизилось до c 6788 до 24, время обработки файла `small.json` снизилось с ~6 до до ~1.9 сек
- проблема транзакций перестала быть главной точкой роста

###  Находка №2
- большое количество обращений к методу fetch_bus `Bus.find_by(name, number)`, `pghero` посоветовал создать индекс на bus_id в таблице `buses_services`
- я добавил составной индекс `add_index :buses, [:number, :model], algorithm: :concurrently` но потом решил кэшировать все автобусы, тем самым избавился от лишнего запроса к базе.
- добавил индекс `add_index :buses_services, :bus_id, algorithm: :concurrently`
- количество запросов `SELECT  "buses".* FROM "buses" WHERE "buses"."number" = $1 AND "buses"."model" = $2 LIMIT $3` свелось к нулю
- проблема транзакций перестала быть главной точкой роста время обработки файла `small.json` снизилось с ~2 до до ~1.4 сек, `medium.json` до 7 сек., `large.json` до ~80 сек.

###  Находка №3
- stackprof wall и ruby_prof walltime callstack указывают на то, что работа `activerecord-import` занимает основное время и все старания по оптимизации ни к чему не приводят.
  - 1312  (  100.0%)  JSONImporter#call
  -  726  (   55.3%)  JSONImporter#import_trips
  -  403  (   30.7%)  JSONImporter#import_buses
  -   56  (    4.3%)  JSONImporter#build_bus
- начал разбираться и понял, что что-то не так с `activerecord-import`, попутно наткнулся на issue https://github.com/zdennis/activerecord-import/issues/615. В итоге нашел причину: чтобы не загружать данный гем при старте Rails в Gemfile при добавлении я проставил `require: false`, но при этом в сервисе надо было сделать `require` дополнительным модулям.
```
require 'activerecord-import' # было
require 'activerecord-import/base' # добавил
require 'activerecord-import/active_record/adapters/postgresql_adapter' # добавил
```
- проблема долгого импорта перестала быть главной точкой роста время обработки файла `small.json` снизилось с ~1.4 до до ~0.2 сек, `medium.json` до 1.4 сек., `large.json` до ~12 сек.

### Находка №4
- `JSONImporter#import_trips`, `JSONImporter#import_buses`, `JSONImporter#build_bus` выполняются независимо друг от друга, идея дальнейшей оптимизации - распараллелить задачи с помощью `concurrent-ruby` добавив при этом количество одновременных подключений к базе


## Рендеринг
###  Находка №1
- страница со 103 записями грузится 570 мс, с помощью `rack-mini-profiler` ознакомился со статистикой рендеринга `trips/index`, увидел, что partial 'trip' разбит на составные части рендеринг которых занимает дополнительное время, так-же присутствуют дополнительные запросы в следствие чего он грузится 28.4 мс
- принял решение оптимизировать запрос с помощью `preload` недостающих ассоциаций
- страница со 103 записями грузится ~380 мс
- проблема множества запросов ушла

###  Находка №2
- по данным `rack-mini-profiler` паршиал `trips/services` рендерится дольше всех - 1.1 - 1.4 мс, для каждого рейса. Так-же `trips/delimeter` каждый раз отнимает время рендеринга
- принял решение объединить паршиалы в один
- страница со 103 записями стала грузится ~90 мс
- проблема долгого рендеринга ушла

###  Находка №3
- по данным `pghero` определил, что не хватает составного индекса на from_id, to_id для trips
- принял решение создать индекс
- страница со 103 записями стала грузится ~60 мс,
- время загрузки сократилось на треть

###  Находка №4
- на данных файла `large.json` загрузка страницы происходит за ~700 мс, это не вписывается в общепринятые стандарты ожидания ответа сервера, в качестве идей для дальнейшей оптимизации, необходимо активировать кэширование или добавить пагинацию

## Защита от регрессии производительности
- добавил спек для фиксации метрики `rspec-benchmark` с пороговым значением 0.2 мс для обработки `small.json`

## Результаты
В результате оптимизации импорта удалось добиться ускорения импорта в 30 раз, при этом для обработки `large.json` требуется 12 сек.
В результате оптимизации индексов, запросов к базе данных и рендеринга страницы `автобусы/Самара/Москва` после импрорта файла `large.json`, удалось добиться ускорения импорта в 14 раз. Страница стала грузиться за ~700 мс. вместо ~10 сек.
