# Case-study оптимизации


 **web оптимизация идет отдельным файлом case-study-web.md**

 **web оптимизация идет отдельным файлом case-study-web.md**
 
 **web оптимизация идет отдельным файлом case-study-web.md**
 
 **web оптимизация идет отдельным файлом case-study-web.md**

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было импортировать большой файл с данными

У нас уже была программа на `ruby`, которая умела это делать, но на большом обьеме (32Мб) дождаться ее завершения не удалось

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: 
время импорта маленького файла json 

time bin/rake reload_json[fixtures/small.json]
real	0m10.243s
user	0m7.906s
sys	0m0.694s


## Гарантия корректности работы оптимизированной программы

Для того чтобы ничего не сломать я вынес логику импорта из рейк таска в класс IMporter
И добавил тест который загружает example.json и сверяет ответ сервера на запрос Москва-Самара с эталоном (до оптимизаций)


## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: 
В качестве фидбек лупа я использовал команду импорта маленького файла
bin/rake reload_json[fixtures/small.json] что позволило тратить 10с на фидбек луп

## Вникаем в детали системы, чтобы найти главные точки роста
Попробуем профилировку в ruby-prof


### Ваша находка №1
Так как профилировку я запустил из rails c 
то обилие запросов сразу вызвало вопросы, аналогичная проблема наблюдалась и в рубипрофе 
почти все время в недрах активрекорда
Попробуем убрать огромное количество запросов к городам и сервисам путем создания кэша в памяти
К автобусам пока не уверен что можно - их возможно очень много

    def city_by_name(name)
        cached = @cities[name]
        
        return cached if cached
       
        city = City.find_or_create_by!(name: name)
        
        @cities[name] = city
    end

Результат есть но очень слабый - всего 20% 
real	0m7.971s
user	0m5.549s
sys	0m0.682s



### Ваша находка №2
Текущий план - максимально уменьшить число запросов убрать ненужные и дальше думать. 
По логу видно что есть много запросов к автобусам по имени, сначала с селектом полей а потом просто exists 
причина этого в проверке уникальности на стороне Rails. Во-первых так как у нас нет потокобезопасности в виде мютексов валидация на стороне rails
еще и не всегда будет правильно работать, поэтому переносим эту задачу на СУБД, к тому же нам все равно нужен индекс по name


    add_index :cities, :name, unique: true
    add_index :buses, :number, unique: true
    
Время все равно уменьшилось не сильно, но зато теперь ничего не стоит между нами и вставкой HABTM    
real	0m7.476s
user	0m5.287s
sys	0m0.644s

Так как новые сервисы и модели автобусов переписывают старые, то можно пойти с конца файла и просто сохранить первые с конца как вилдные

    real	0m5.450s
    user	0m4.410s
    sys	0m0.408s



### Ваша находка №3

Будем импортить пачками с помощью ActiveRecord-import
Начнем с trips


        trips << Trip.new(
            from: from,
            to: to,
            bus: bus,
            start_time: trip['start_time'],
            duration_minutes: trip['duration_minutes'],
            price_cents: trip['price_cents'],
        )


        if trips.count > TRIPS_BATCH_SIZE
          Trip.import trips
          trips = []
        end

Время импорта большого файла почти уложилось в минуту

    real	1m21.265s
    user	1m4.696s
    sys	0m4.158s




### Ваша находка №4 

StackProf показал что 83% времени мы в find_or_create_by
А у нас всего 1 место такое

    bus = Bus.find_or_create_by!(number: trip['bus']['number']) do |b|
      b.model = trip['bus']['model']
      b.services = trip['bus']['services'].collect(&method(:service_by_name))
    end

Для проверки я убрал строку с сервисами 

    b.services = trip['bus']['services'].collect(&method(:service_by_name))

Все еще 73% в find_by внутри find_or_create_by ну выбора нет попробуем накапливать данные по автобусам в памяти

Результат ожидаем рост в почти 3 раза и тесты сходятся

    real	0m30.706s
    user	0m26.815s
    sys	0m0.707s


## Результаты

Удалось уложиться во в 2 раза меньшее время чем бюджет, здорово

## Защита от регрессии производительности

Дабы такое не повторялось я написал тест проверяющий производительность 

      it 'import performance test ' do
        expect { Importer.new.import('fixtures/example.json') }.to perform_under(40).ms.warmup(1).times.sample(10).times
      end



# web оптимизация идет отдельным файлом case-study-web.md