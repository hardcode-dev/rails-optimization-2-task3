# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникли 2 проблемы.
1) Необходимо было импортировать в базу файл с данными, чуть больше 32 мегабайт (100К записей).
   Рейк таск успешно работал на файлах размером пару мегабайт, но c большими файлами он работал слишком долго.
   Я решил исправить эту проблему, оптимизировав этот скрипт.

2) Страницы расписаний тоже формируются не эффективно и при росте количества записей начинают сильно тормозить.
   Я решил исправить эту проблему, оптимизировав sql-запросы.
   
## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:
время выполнения программы/запроса в секундах.

Бюджет метрики для импорта large.json - 60 секунд.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась без теста. Поэтому необходимо было написать тест, проверяющий корректность работы программы.
Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`,
который позволил мне получать обратную связь по эффективности сделанных изменений за ~15 секунд

Вот как я построил `feedback_loop`:
- написал тесты для проверки корректности работы рейк таски/контроллера
- измерил метрику: время выполнения рейк таски с example.json (10 записей) - 200 мс,
  время ответа для контроллера с записями из large.json (1000 рейсов) - `25548ms (Views: 23577.9ms | ActiveRecord: 1962.8ms)`
- написал performance тесты для защиты от деградации производительности
- далее использовал эти же входные данные для дальнейшего профилирования и сравнения метрик

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался:
- rack-mini-profiler
- rails panel
- bullet
- PgHero

Вот какие проблемы удалось найти и решить:

Ваша находка №1
- Стандартный лог в консоли показал, что выполняется очень много sql запросов при импорте
- Переписал рейк таск с использованием библиотеки activerecord-import, каждая таблица заполняется одним запросом,
  в том числе и join-таблица buses_services.
- Метрика уменьшилась с 200 до 25 мс для small.json
- Количество sql запросов в логе сильно уменьшилось. Прогон large.txt занимает 47 секунд - уложились в бюджет.

Ваша находка №2
- Отчет bullet показал что в контроллере не хватает eager loading
- Добавил `.includes(bus: [:services])`
- Время ответа сервера уменьшилось с
  
    `25548ms (Views: 23577.9ms | ActiveRecord: 1962.8ms)`, до
    
    `22393ms (Views: 22124.9ms | ActiveRecord: 240.2ms)`
- Bullet больше не показывает ворнингов

Ваша находка №3
- Rails panel показал,что на рендеринг уходит около 20 секунд
- Перенес все паршиалы в одну вьюху
- Время ответа сервера уменьшилось до `1445ms (Views: 1245.1ms | ActiveRecord: 188.4ms)`
- Время рендера вьюхи сократилось до 1,2 с

Ваша находка №4
- PGHero предлагает построить индексы для 3 самых долгих запросов
- Построил эти индексы
- Время ответа сервера почти не изменилось: `1524ms (Views: 1473.3ms | ActiveRecord: 36.5ms)`
- PGHero больше не предлагает строить индексы

Ваша находка №5
- rake-mini-profiler показал, что вызывается лишний sql запрос для количества рейсов
- Заменил `@trips.count` на `@trips.load.size` во вьюхе
- Время ответа сервера уменьшилось до `1329ms (Views: 1232.9ms | ActiveRecord: 58.5ms)`
- В отчете rake-mini-profiler на один sql запрос меньше

## Результаты
В результате проделанной оптимизации удалось улучшить метрику импорта 100К записей до 47 секунд и
уложиться в заданный бюджет.
Также удалось уменьшить время ответа сервера для 1000 рейсов с 25 секунд до 1,3 секунды.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях были написаны performance-тесты на время выполнения.
