# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникло несколько серьёзных проблема.

1. Импорт данных занимает слишком большое количество времени. 
  Необходимо оптимизировать процесс импорта данных в систему. Бюджет для данной задачи: импорт `100K трипов` меньше чем за `60 sec`
2. Отображение расписаний формируется не эффективно и тормозит при больших объемах данных
  Нужно найти и устранить проблемы, замедляющие формирование этих страниц. Строгого бюджета нет 

## Формирование метрики

### Импорт данных

Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: 
- время выполнения на файле уменьшенного размера

### Формирование данных и рендеринг
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: 
- Делать замеры постепенно наращивая объем данных, которые хранятся в БД

## Гарантия корректности работы оптимизированной программы
Программа поставлялась без тестоа. Поэтому перед тем как приступить к оптимизации, я покрою текущее состояние тестами, 
что бы в дальнейшем быть уверенным в том, что мои изменения не внесут багов в работу системы.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений

### Импорт данных

`feedback_loop`:
 - Создал набор тестовых файлов меньшего размера
 - Нашел Главную Точку Роста
 - Исправил ее
 - Проверил тест

### Формирование данных и рендеринг

`feedback_loop`:
 - Нашел Главную Точку Роста
 - Исправил ее

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался несколькими профилировщиками.

Вот какие проблемы удалось найти и решить

### Импорт данных

Оптимизации я решил начать с импорта данных в БД.

#### Точка роста №1 

Для нахождения первой точки роста я сначала попробовал измерять выполнение с помощью `pghero`.
Результаты метрик ничего особого не дали, потому что я увидел в результатах огромное кол-во запросов, которые выполнялись очень быстро и очень много раз.
Выделить какую то одну точку не получилось. 

Тогда я решил попробовать снять метрики с помощью `ruby-prof`, что бы посмотреть, куда тратится большая часть процессорного времени.  
К сожалению это тоже не внесло никакой конкретики.

Вернулся обратно анализу метрик `pghero`. 
Нашел самые часто вызываемые запросы. Ими оказались:
- Запрос на получение `services`
- Запрос на получение `bus_services`

Изучив модель БД, понял что здесь можно попробовать денормализировать модель, т.к. сервисов у нас всего 10 и это позволит значительно сократить кол-во запросов к БД. 

Перед рефакторингом, решил снять метрику по врмени выполнения, что бы затем было с чем сравнить:
- `small.json` - `10.85 sec`
- `medium.json` -- `92.87 sec`

Перед тем как вносить изменения, добавил и настроил гем `strong_migrations`.

Какие изменения были внесены:
- добавил колонку `services` в таблицу `buses`
- удалил таблицы `services` и `buses_services`
- Добавил кастомный валидатор: `ArrayInclusionValidator`

После внедрения этих изменений снял показания:

- `small.json` - `4.93 sec`
- `medium.json` -- `46.46 sec`

#### Точка роста №2

После введенных изменений на первом шаге решил продолжить исследовать структуру БД и метрики по запросам.
 
Обнаружил, что во время выполнения часто вызыввается `select` на таблицах `buses` и `cities`.
Причина этого: использование `find_or_create_by`. 
Для начала решил вынести проверки на уникальность на уровень БД с помощью индекса.

После внедрения этих изменений снял показания:

- `small.json` - `4.11 sec`
- `medium.json` -- `35.94 sec`

Изменения не дали большого эфекта в целом. Скорее всего из-за того, что был оптимизирован процесс поиска данных, но из-за индекса увеличилось время записи. 
Как видно по результатам с ростом кол-ва записей в файле, удучшение чувствуется ощутимей.

#### Точка роста №3

Частый вызов `select` на таблице `cities` все так же в топе для `pghero`.
Взглянув на то как используется эта таблица понял, что в ней всегда используется только аттрибут `name`. 
Решил опять применить денормализацию.
- Удалил таблицу `cities` 
- Добавил колнки `from` и `to` в `trips`

После внедрения этих изменений снял показания:

- `small.json` - `3.00 sec`
- `medium.json` -- `19.30 sec`

#### Точка роста №4

Теперь в топе вызовов `insert`-ы в таблицы. Кажется пришло время внедрить `activerecord-import` 
- Добавил `activerecord-import`
- Добавил `constraint` на уникальность поля `number` в таблице `buses`
- Рефакторинг таски для импорта данных

После внедрения этих изменений снял показания:

- `small.json` - `0.47 sec`
- `medium.json` -- `4.24 sec`
- `large.json` -- `44.39 sec`

После этой оптимизации, мы укладываемся в наш бюджет по импорту данных из файла `large.json` меньше чем за `60 sec`

### Рефакторинг текущего состояния

Перед тем как перейти к оптимизации `Формирование данных и рендеринг`, нужно починить то, что изменилось во время проведения рефакторинга. 

### Формирование данных и рендеринг

Так как по Импорту данных мы стали укладываться в бюджет можно перейти к оптимизации процесса `Формирование данных и рендеринг`

### Точка роста №1

Для профилирования на этом шаге я использовал `rack-mini-profiler`. 
Профилировщик указал, что основной точкой роста является рендеринг.
Общее время загрузки страницы `~2000 ms`.
 
Профилировщик указал, что на рендеринг приходится `~65 %` общего времени.
Причем большая часть времени уходит на рендеринг `partials`. 
Поэтому в этом шаге я решил максимально уйти от их использования. 
Как результат время сократилось примерно в `2 раза` и теперь составляет примерно `1000 ms`
 
### Точка роста №2

Я заметил, что выполняется большое кол-во дублирующихся запросов к БД. Это указывает на то, что в системе присутствует проблема `N+1`.
Установил gem `bullet`. Он и правда указал на `N+1` при обращении к `Bus` модели. 
Добавил прелоадинг `Bus` модели и время загрузки страницы сократилось до `~400 ms` 

### Точка роста №3
 
На этом шаге я решил вернуться к `pghero`. В топе по выполнению у него был запрос на подсчет кол-ва `trips`.
Я заменил вызов метода `count` на `length` так как в данном случае нам нет надобности обращаться в БД.
Это сократило время загрузки примерно на `90 ms`

### Точка роста №4

В топе у `pghero` еще остался запрос на получение "поездок". Им я и решил заняться.
Проведя анализ, стало понятно, что проблема в том, что в нем не хватает индексов.

После добавления индексов время получения "поездок" сократилось до `~1 ms`
 
## Результаты

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
