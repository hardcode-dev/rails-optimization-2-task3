# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было импортировать большой файл с данными

У нас уже была программа на `ruby`, которая умела это делать, но на большом обьеме (32Мб) дождаться ее завершения не удалось

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: 
время импорта маленького файла json 

time bin/rake reload_json[fixtures/small.json]
real	0m10.243s
user	0m7.906s
sys	0m0.694s


## Гарантия корректности работы оптимизированной программы

Для того чтобы ничего не сломать я вынес логику импорта из рейк таска в класс IMporter
И добавил тест который загружает example.json и сверяет ответ сервера на запрос Москва-Самара с эталоном (до оптимизаций)


## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: 
В качестве фидбек лупа я использовал команду импорта маленького файла
bin/rake reload_json[fixtures/small.json] что позволило тратить 10с на фидбек луп

## Вникаем в детали системы, чтобы найти главные точки роста
Попробуем профилировку в ruby-prof


### Ваша находка №1
Так как профилировку я запустил из rails c 
то обилие запросов сразу вызвало вопросы, аналогичная проблема наблюдалась и в рубипрофе 
почти все время в недрах активрекорда
Попробуем убрать огромное количество запросов к городам и сервисам путем создания кэша в памяти
К автобусам пока не уверен что можно - их возможно очень много

    def city_by_name(name)
        cached = @cities[name]
        
        return cached if cached
       
        city = City.find_or_create_by!(name: name)
        
        @cities[name] = city
    end

Результат есть но очень слабый - всего 20% 
real	0m7.971s
user	0m5.549s
sys	0m0.682s



### Ваша находка №2
Текущий план - максимально уменьшить число запросов убрать ненужные и дальше думать. 
По логу видно что есть много запросов к автобусам по имени, сначала с селектом полей а потом просто exists 
причина этого в проверке уникальности на стороне Rails. Во-первых так как у нас нет потокобезопасности в виде мютексов валидация на стороне rails
еще и не всегда будет правильно работать, поэтому переносим эту задачу на СУБД, к тому же нам все равно нужен индекс по name


    add_index :cities, :name, unique: true
    add_index :buses, :number, unique: true
    
Время все равно уменьшилось не сильно, но зато теперь ничего не стоит между нами и вставкой HABTM    
real	0m7.476s
user	0m5.287s
sys	0m0.644s

## Результаты


## Защита от регрессии производительности

