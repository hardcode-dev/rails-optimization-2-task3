# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.
У нас уже была программа, которая умела делать нужную обработку.

Необходимо было обработать файл с данными, чуть больше 30 мегабайт.
Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго.

Я решил исправить эту проблему, оптимизировав эту программу.
И страница с расписанием, с увеличением числа рейсов - так же замедляется.
При 1млн строк в базе и 58рейсов "Самара – Москва" грузится за 1300мс. Поставим цель - 1000  

Новая цель - программа должна обрабатывать этот файл не более чем за 60 секунд

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я 
решил использовать тесты замеряющие время выполнение программы. Напишем сразу на разные размеры файлов.  
На момент старта оптимизации имеем следующие значения:
small.json = 12 секунд
medium.json = 95 секунд
large.json = (дофига) секунд


## Гарантия корректности работы оптимизированной программы
Выполнение тестов в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации. 
Поэтому перед началом работы напишем тесты на корректность работы. 


## Feedback-Loop
1. Запускаем различные профилировщики, выявляем проблемные места
2. Вносим свои правки
3. Тестируем на работоспособность
4. Замеряем производительность

### STEP-0 Начало работы 
1. Развертываем систему
2. Пишем тесты 
3. Настраиваем профилировщики
4. Замеряем производительность (medium:95с, large:много)

### STEP-1
1. Смотрим в pghero - на что уходит больше всего времени; Видим что очень много запросов идет к справочным данным(автобусы, города и т.д.).
2. Так как справочных данных точно меньше рейсов - не будем искать эти значения на каждой итерации.
3. Замеряем производительность (medium:36с, large:284c). Ускорение почти 3 раза, хороший результат. Идем дальше 

### STEP-2 
1. Смотрим ruby-prof. Видим что много времени занимает команда update у автобусов.
2. Так автобус всегда одинаковый - не зачем изменять каждый раз его параметры. Будет записывать данные при создание автобуса и все.
3. Замеряем производительность (medium:20с, large:184c). Не плохо. Идем дальше 

### STEP-3
1. Смотрим pghero. Видим что сейчас время уходит на создание trips-ов. 
2. Нужно переделывать добавление на поток. Сперва была идея - сделать через activerecord-import, но решил сделать потоковою сразу в Postgres, так как так еще никогда не делал.
2.1 В ходе дела выяснилось - что во время поточной записи не выходит создавать справочные записи. Пробуем - такой вариант: Обходим сперва файл, создавая справочники. А потом поточно записываем trips-ы. 
3. Замеряем производительность (medium:11с, large:27c). Ура! Мы сразу же укладываемся в бюджет с запасом
4. Файл mega - 3.5минуты. hardcore - 31минута(съела 13г озу. Плохо. Но в рамках данной задачи оптимизировать не будем)

### STEP-4
1. Переходим к задаче с отображением. Смотрим Rails-panel. Видим много однотипных запросов
2. Минимизируем запросы к базе. 
3. Замеряем производительность c 1300мс - дошли до 600мс. улучшение в 2 раза, отлично. Идем дальше

### STEP-5
1. Смотрим Rack::MiniProfiler. Видим что сейчас основная точка роста - это парсинг паршелов
2. Убираем лишние шаблоны.
3. Замеряем производительность c 600мс - дошли до 230мс. не плохо. Идем дальше
 
### STEP-6
1. Смотрим Rails-panel/Rack::MiniProfiler. Видим что сейчас основная точка роста - это время выполнения запросов.  
2. Делаем explain самого нагруженого. Видим что нужен индекс по полям start_time и (to_id, from_id) (pghero - тоже подсказывает). Создаем
3. Замеряем производительность c 230мс - дошли до 110мс. не плохо. Идем дальше
 
### STEP-7
1. Смотрим Rails-panel/Rack::MiniProfiler. Видим что сейчас основная точка роста - это оставшийся паршел. 
2. Убираем его тоже
3. Замеряем производительность c 110мс - дошли до 75мс. Отлично. Укладываемся в бюджет
 

## Результаты
- научился работать с инструментами: pghero, Rails-panel, RackMiniProfiler
- Научился делать потоковую запись в Postgres из json. По примеру из задания.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы - написали небольшой тест для проверки скорости импорта.
