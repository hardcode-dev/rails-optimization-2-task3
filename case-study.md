# Case-study оптимизации

## Актуальные проблемы

### Проблема 1. Импорт данных

В проекте есть `rake` задача, которая загружает данные о рейсах из `json` файла.
Файлы с примерами:
* `example.json` (10 рейсов)
* `small.json`  (1K рейсов)
* `medium.json`  (10K рейсов)
* `large.json`  (100K рейсов)

Загрузка делается очень не эффективно и медленно:
* `example.json` Finish in 0.19 s (2 MB)
* `small.json` Finish in 7.76 s (12 MB)
* `medium.json` Finish in 61.35 s (43 MB)
* `large.json` Finish in 616.38 s (228 MB)

10 минут на 100K сущностей - как-то многовато =)

Нужно оптимизировать механизм перезагрузки расписания из файла так, чтобы он импортировал файл `large.json`  **в пределах минуты**.


### Проблема 2. Отображение расписаний

В проекте есть `action`, который формирует страницу расписаний (например по пути `автобусы/Самара/Москва`)

Сами страницы расписаний тоже формируются не эффективно и при росте объёмов начинают сильно тормозить.

На объеме `large.json` страница рендерится 6 секунд.

`Completed 200 OK in 6365ms (Views: 4350.7ms | ActiveRecord: 1998.5ms)`

Нужно найти и устранить проблемы, замедляющие формирование этих страниц.


### Проблема 3. Импорт больших файлов

Нужно справиться с импортом файлов `1M.json` (`codename mega`) и `10M.json` (`codename hardcore`).

Файл `10M.json` весит ~ `3Gb`. Поэтому лучше не пытаться грузить его целиком в память и парсить. Вместо этого лучше читать и парсить его потоково.

Есть набросок потокового чтения из файла с потоковой записью в `Postgres`...


# Оптимизация


## Решение проблемы 1. Оптимизация импорта данных

Для удобства вынес код импорта в отдельный класс-утилиту `ReloadJsonUtil`.

Добавил также класс `BenchmarkUtil` с методами для подсчета времени выполнения через `Benchmark.realtime` и используемой памяти через ``` ps -o rss= -p #{Process.pid}`.to_i / 1024```

Для защиты от регрессии написал два теста:
1. на проверку корректности загрузки файла `example.json`
2. на проверку времени загрузки: файл `small.json` должен загружаться не дольше 10 мс

Для удобства команды запуска прописал в `Makefile`
```
.PHONY: test  
  
all: test small  
test:  
  rails test  
example:  
  rails 'reload_json[fixtures/example.json]'  
small:  
  rails 'reload_json[fixtures/small.json]'  
medium:  
  rails 'reload_json[fixtures/medium.json]'  
large:  
  rails 'reload_json[fixtures/large.json]'  
one_by_one: example small medium large

```

Теперь при запуске `make` запускаются тесты и происходит загрузка файла `example.json` - получил эффективный **Feedback-Loop**

К сожалению, профилирование такими инструментами как `ruby-prof` результата не принесло из-за наличия в топе объектов инфраструктуры `Rails`. Поэтому будем смотреть логи и воспользуемся гемом [activerecord-import](https://github.com/zdennis/activerecord-import)

По логам стало понятно что скрипт импорта делает много лишних запросов в БД.

Для избежания лишних запросов будем накапливать данные вспомогательных таблиц (по инсайдерской информации городов и автобусов относительно не много) в хешах и получать необходимые значения по соответствующему ключу. После чего сделаем импорт через `activerecord-import`.

Воспользовался инсайдерской информацией, что сервисов ровно 10 --- сделал импорт прямо из константы `Service::SERVICES`

В результате проделанной оптимизации:
* `example.json` Finish in 0.47 (7 MB)
* `small.json` Finish in 1.12 (32 MB)
* `medium.json` Finish in 3.95 (126 MB)
* `large.json` Finish in 32.64 (770 MB)

**Цель достигнута** - импорт файла `large.json` выполняется за ~ **35 секунд**

Можно обновить тест на проверку времени загрузки: файл `small.json` должен загружаться не дольше 2 ms.

В дальнейшем можно провести оптимизацию по памяти (сейчас при импорте `large.json` используется около 806 MB, но мой взгляд вполне приемлемо =)).


## Решение проблемы 2. Оптимизация отображения расписаний

Для меня самой удобным инструментом в этом задании оказались `логи Rails`, но попробовать инструменты тоже надо. Исключение, пожалуй, `pghero` - очень хороший инструмент.
`rails panel` - забыть как страшный сон =)

На объеме `large.json` страница рендерится 6 секунд.

`Completed 200 OK in 6365ms (Views: 4350.7ms | ActiveRecord: 1998.5ms)`


### Находка 1

Наивысшая точка роста - рендеринг `Views: 4832.8ms`.

Пробуем `rack-mini-profiler`:
* Время загрузки увеличилось
`Completed 200 OK in 13776ms (Views: 10016.1ms | ActiveRecord: 3758.5ms)` 
* в профайлере на фронте: `Rendering: trips/index.html.erb`
	* duration(ms): `5545.6`
	* query time (ms): `657 sql - 1126.8`
* Проблема та же: рендеринг большого кол-ва partial

Вьюхи довольно простые, поэтому отказался от теста и остановился на аккуратном копи-пасте.

Сократил partial'ы в пользу `render collection`.
Немного поправил верстку - перенес вложенный `ul` сервисов во внутрь соответствующего тега `li`

`Completed 200 OK in 2310ms (Views: 1222.1ms | ActiveRecord: 1086.1ms)`

**Профит - почти 4 секунды**


### Находка 2

По логам явно видна проблема N+1.
`CACHE Bus Load`
`CACHE Service Load`

Попробовал воспользоваться `bullet` - он честно предложил добавить `.includes([:bus])`, (но также замедлил рендеринг).

На вкладке `Queries` `pghero` также можно заметить в топе большое кол-во легких запросов `SELECT "services".*` и `SELECT "buses".*`

`pghero` также предложил добавить индекс `CREATE INDEX CONCURRENTLY ON trips (from_id, to_id)`, что мы и сделаем немного позже.

Добавил `.eager_load(bus: :services)` к запросу:

`Completed 200 OK in 224ms (Views: 167.5ms | ActiveRecord: 54.8ms)`

**Профит - почти в 10 раз**


### Находка 3

Лишний запрос `SELECT COUNT`, который тратит `15ms` - меняем `@trips.count` на `@trips.load.size`

`Completed 200 OK in 207ms (Views: 181.1ms | ActiveRecord: 24.6ms)`

### Находка 4

Пробуем `explain` запросов через `pghero` + [Postgres Explain Visualizer](https://tatiyants.com/pev/#/plans/new)

Явно не хватает индекса: `SEQ SCAN 87.9ms | 96% on public.trips  (trips)`

Добавил индекс `add_index :trips, [:from_id, :to_id], algorithm: :concurrently`

`Completed 200 OK in 188ms (Views: 175.2ms | ActiveRecord: 11.2ms)`

**Профит по ActiveRecord - почти в 2 раза**

Итог --- страница `автобусы/Самара/Москва` загружается за `~200ms` (иногда `max 250ms`)


## Решение проблемы 3. Импорт больших файлов

### Plan

* чистим базу
* идём по огромному файлу
* по пути формируем в памяти вспомогательные справочники ограниченного размера (`cities`,  `buses`,  `buses_services`)
* сразу же стримим основные данные в базу (`trips`), чтобы не накапливать их
* после завершения файла сохраняем в базу сформированные справочники

### Мета-информация о данных

При реализации импорта нужно учесть инсайдерские знания о данных:
* первичным ключом для автобуса считаем  `(model, number)`
* уникальных автобусов в файле  `10M.json`  ~  `10_000`
* уникальных городов в файле  `10M.json`  ~  `100`
* сервисов ровно  `10`, те что перечислены в  `Service::SERVICES`

Заметим, что `buses_services` будет не больше `100_000` (`10_000` * `10`)

То есть таблицы не большие и их можно накопить в памяти, а потом воспользоваться `activerecord-import`.
Сервисов ровно 10 - сделал импорт прямо из константы `Service::SERVICES`.

Реализуем задуманное. Результаты:

*  `example.json` Finish in 0.1 (1 MB)
*  `small.json` Finish in 0.53 (10 MB)
*  `medium.json` Finish in 1.33 (11 MB)
*  `large.json` Finish in 8.29 (8 MB)
* `mega.json` Finish in 94.55 (31 MB) - 1 min 34 sec
* `hardcore.json` Finish in 850.36 (35 MB) - 14 min 10 sec


Импорт `10M.json` (`codename hardcore`) выполняется за ~`15` минут!

