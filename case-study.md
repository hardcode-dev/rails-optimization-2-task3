# Case-study оптимизации

## Актуальная проблема: Импорт данных
К приложению поставляются файлы для импорта рейсов, но скрипт для их загрузки в БД работает очень долго для большого количества рейсов:
- `small.json` (1K рейсов) - 16,4 сек
- `medium.json` (10K рейсов) - 131 сек
- `large.json` (100K рейсов) - **не измерял**, но должны уложиться в бюджет в **пределах минуты**

Будем использовать в качестве метрики загрузку файла с 1К рейсов - **16,4 сек**

### Гарантия корректности работы оптимизированного скрипта
Перенёс работу скрипта в сервис и написал для него тест:
```ruby
context 'Correct trips import' do
  let(:trip_from_file) { JSON.parse(File.read('fixtures/example.json')) }
  
  before { ImportTripsService.call('fixtures/example.json') }

  it 'trips from DB are equal to imported' do
    expect(Trip.all.map(&:to_h).sort_by(&:to_s)).to eq trip_from_file.sort_by(&:to_s)
  end    
end
```
Полученные из DB отсортированные рейсы должны быть эквивалентными рейсам из файла. Для проверки немного подкорректировал метод `Trip#to_f`

### Feedback-Loop
Для эффективной работы по оптимизации выстроил `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений.
- Поставил pgHero для изучения поведения запросов
- В самом скрипте провожу замер скорости выполнения
- В тесте сервиса слежу, чтобы проводимые изменения не ломали логику выполнения импорта рейсов


### Находка №1 - большое количество запросов SELECT
Изучаем статистику pgHero, обращаем внимание на некоторые нюансы которые видишь впервые:
- `pkeys` весят соизмеримо с самими талицами
- При импорте - сами запросы простые, но их количество слишком большое - **12861** запрос на **1000** рейсов
Сравниваю запросы с кодом скрипта - нахожу строки где вызывается их выполнение. Провожу рефакторинг - в основном добавил хранение City, Service и Bus во временных хэшах.
- Метрика изменилась: 1К рейсов - с **16,4 сек** до **7,5 сек**. Самих запросов SELECT стало значительно меньше - < 4000

### Находка №2 - добавление индекса к автобусам
Дальнейшее изучение pgHero показывает, что 44% тратится на INSERT INTO trips и 23% SELECT from buses. Сами рейсы пока трогать не будем, добавим индекс к автобусам. 
*тогда ещё не был поставлен гем strong_migration, а так он бы поругался, что не хватает concurrency*
```ruby
add_index :buses, :number, unique: true
```
- SELECT автобусов стал занимать 12%, а общая загрузка уменьшилась до **6,9 сек**

### Находка 3 - activerecord-import
Становится понятно, что основное время тратится на обращение и подключение к БД при создании объектов, поэтому думаем как это обойти. Для этого будем использовать гем `activerecord-import`, который позволяет сохранить все объекты помещённые во временное хранилище за раз. Добавляем эту возможность в скрипт. Всё работает очень быстро, но тут падает тест на логику импорта - в базе не сохраняются сервисы автобусов. 
Изучение этой проблемы показало что `activerecord-import` не поддерживает ассоциации (хотя в описании должен). Небольшое ознакомление с проблемой, показало, что не я один сталкивался с ней, но простого решения для неё нет.
Тогда добавим модель `BusesService` к соединительной таблице `buses_servises`, и собираем и сохраняем объекты тоже отдельно.
- Метрика изменилась: 1К рейсов - с **6,9 сек** до **1,5 сек**. Ура!

### Попадание в метрику. Выводы. Тесты
Теперь можно проводить замер и на `large.json` - **55 сек** - как раз укладываемся в метрику!
Стало интересно сколько тратится памяти при таком импорте данных:
- small  - 1.5 sec - 113 MB
- medium - 7 sec   - 181 MB
- large  - 55 sec  - 732 MB

Думал, что с увеличением количества рейсов памяти будет расходоваться больше. Наверное, из-за того что данные повторяются не происходит большой расход памяти.
Можно было попробовать обновить версию `rails` до 6 и использовать `insert_all`, или переписать импорт на потоковый режим, чтобы попытаться осилить файлы побольше, но так как имеется отставание по времени прохождения курса - переходим ко второй части ДЗ.
- Защитил скрипт тестом, время импорта 1000 рейсов не должно быть больше 2-х сек
```ruby
expect { ImportTripsService.call('fixtures/small.json') }.to perform_under(2).sec
```

## Актуальная проблема: Отображение расписаний
Когда рейсов становится слишком много страница с расписанием грузится очень медленно.
С файлом `small` время страницы `http://localhost:3000/автобусы/Самара/Москва` - 579ms

### Находка 1 - чрезмерная загрузка паршиалов + COUNT
Первым делом изучаем логи сервера:
```log
Completed 200 OK in 579ms (Views: 475.8ms | ActiveRecord: 81.6ms)
```
Большая часть времени - загрузка вьюх. И много времени уходит на запрос COUNT (@trips.count). Помним, что это всегда лишний запрос, поэтому меняем на #size. Эффекта нет - запрос COUNT продолжает отправляться. Пробуем #length - помогает. *Интересно, как в современных рельсах работает вопрос о размере*
Рефакторим вьюхи и меняем count на length:
```log
Completed 200 OK in 180ms (Views: 107.2ms | ActiveRecord: 70.1ms)
```
Наблюдаем положительный эффект и там и там

### Находка 2 Eager loading
Так как тема текущего урока - оптимизация БД, а не вьюх - увеличиваем количество рейсов до 10000 (medium.json). Время загрузки - 800 мс
Ставим `bullet` - он советует добавить:
- includes([:bus])
- includes([:services])
Получаем время загрузки вместо **800 мс - 155 мс**. Помним о `preload` - ставим его вместо `includes`, но разницы по времени вообще не получаем, поэтому оставляем `includes` - как и советовал изначально `bullet`

### Находка 3 - индексы
Увеличиваем кол-во рейсов до 100к. Наш запрос занимает 600 мс. Из них 530 - вьюха, 48 - AR
Уже до этого ставили `rack-mini-profiler`, но знакомился с ним поверхностно - обращал внимание только на общее время загрузки страницы. Теперь решил изучить подробнее. Большое положительное удивление доставило количество опций - когда можно открывать отчёт с другими профилировщиками. Когда видишь это на уроке - не проникаешься его мощью. Но когда уже все запросы как родные - `rack-mini-profiler` может заменить почти всё остальное (наверное)

Изучение `pgHero` и `rack-mini-profiler` показывает, что **41%** времени занимает занимает запрос рейсов где идёт поис `from_id` -> `to_id` - Значит, это первый претендент на индекс.

Перед добавлением индексов ставим:
- strong_migrations
- rails panel
- rails_performance (вообще ничего интересного не показал)

Добавляем индекс к
- cities :names
- trips [:from_id, :to_id]
`strong_migrations` предлагает использовать опции `disable_ddl_transaction!`, `algorithm: :concurrently` - окей, мы для этого его и ставили.
Получаем загрузку ActiveRecord: 18 ms. Загрузка вьюх остаётя прежней. 

Считаю, оптимизации загрузки страниц с рейсами мы добились.

### Попадание в метрику. Выводы. Тесты
Итак страница с 1004 рейсами из 100_000 грузится за 485ms, из которых работа с БД - 20 ms. Возможно можно добавить пагинацию, или соорудить один мощный запрос, но уже поджимает время сдачи. Считаю что попадаем в метрику загрузки страницы с рейсами.

Пишем тест для защиты полученных результатов в оптимизации. Он заключается в том, что экшен trips#index с параметрами Самара -> Москва должен отработать менее чем за 5 мс (100 000 записей в БД)
```ruby
  describe 'GET #index' do
    before { ImportTripsService.call('fixtures/medium.json') }

    it 'load 10 000 trips under 5 ms' do
      expect { get :index, params: { from: 'Самара', to: 'Москва' } }.to perform_under(5).ms
    end
  end
  ```

