# Case-study оптимизации

## Актуальная проблема
В проекте имеется 2 проблемы:
* Долгий импорт данных из файла
* Неоптимальная работа с данными на фронте 

Я решил исправить эту проблему, оптимизировав код.

## Проблема 1
### Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие импорта, была выбрана следующая метрика: время работы скрипта в секундах
Бюджет составляет 60 секунд

## Гарантия корректности работы оптимизированной программы
Для того, чтобы обезопасить код от дальнейшей регрессии, написан тест на быстродействие выполнения программы

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за +- 10 секунд:
* Для начала определился с комфортным для тестов файлом - `fixtures/medium.json`
* Далее идет итеративный процесс оптимизации:
    * Посмотрел, что происходит при импорте данных в `pg_hero` (на самом деле лишь в начале и в конце, хватило беглого взгляда на код)
    * Вносил изменения
    * Замерял скорость работы программы

### Находка №1
- выполнялось какое-то невменяемое количество запросов
- вынес код в отдельный сервис (заводить код в консоли ну куда удобней, тесты писать тоже проще)
- переписал код согласно плану - копил данные в памяти и записал их при помощи гема https://github.com/zdennis/activerecord-import
- Немножечко дописал модели, чтобы было удобней
- замерял время работы скрипта - уложился в бюджет - ~35 секунд (что было со временем до этого - не знаю, не долждался :))
- программа кушает достаточно много памяти - около 700mb - оставил на бонус, если будет время

### Находка №2
- в консоли увидел, что грузится миллион паршелов
- переписал код в одну вьюху - стало быстрее, с 30сек до 15сек

### Находка №3
- буллет сказал, что нет подгрузок данных
- добавил eager_load
- рендер стал занимать около 3 сек

## Результаты
В результате проделанной оптимизации наконец удалось сделать относительно быстрый импорт файла и оптимизировать отображение информации

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы написал тест на скорость импорта данных

##bonus
Обязательно сделаю, но уже в совсем свободное время от курса. Фактически больше настраивал окружение.
Еще немного расстроило, что половина инструментов применима только для посгрес. Я понимаю, что он сейчас типа легаси, но все же.
У нас в проекте MariaDB. Может быть, есть какие-то рекомендации помимо гугла или личный опыт? Хочется что-то вроде `pg_hero`
Ну или перекатываться на PG каким-то чудом