#### Решение задачи №3

#### Первая часть
Обозначим проблему - очень долгая загрузка файла data_large.json
Обозначим основную метрику и бюджет: основная метрика - время загрузки файла, оптимальный бюджет - 1 минута для data_large
#### Выстроим feeedback loop
1. Для начала обойдемся банальным rspec-benchmark для банального замера времени
Для более удобной работы вынесим из рейк таски основные действия в отдельный сервис класс (удобно и понятно тестировать)
Включим pgbadger для построения отчетов

#### Оптимизация по Feeback loop
1. При помощи отчета pgbadger и простенького теста обнаружил что даже средний файл уже не помешается в бюджет, а конкретно отчет показал что у нас проблема даже не с записью в БД а из за того что из нее постоянно что то селектят. 1,6k селектов на 55 инсертов при маленьком файле

2. Среднее число записей уже не укладывается в бюджет, отчет pgbadger показывает уверенные точки роста (больше селектов чем инсертов) а так же указывает на самый медленный запрос (10 секунд для запроса который выбирает сервисы по id автобуса)
Начнем рефакторинг и переезд на acitverecord_import. Для этого сначала напишем простенький тест для проверки что ничего не сломали, а потом уже начнем переделывать экспорт.
Результат - после выноса в словари средний файл начал укладываться в бюджет. Показатели селектов сильно не упали

3. Продолжаем ориентироваться на спеку и отчет bgbadger - снижаем количество селектов. Продолжаем рефакторинг блока.
Полностью ушел в activerecord_import и влез в бюджет 30 секунд для large.json. Отчет уже явно не указывает на частые селекты. Можно копать дальше но перехожу ко второму заданию - время не позволяет

#### Вторая часть

