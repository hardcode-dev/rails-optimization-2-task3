# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было импортировать в базу файл с данными, чуть больше 32 мегабайт (100К записей).

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: *Время выполнения программы*

Для начала используя ассимптотку я сделал предположение о том, сколько будет работать программа на больших данных.
Для этого я написал простой тест, который запускает программу, передавая ей в качестве аргумента нужный файл

### Результаты:
* 10 записей ~ 0.15 s
* 1000 записей ~ 8,90 s
* 10000 записей ~ 73.98 s
* 100000 записей ~ 12 min

Бюджет метрики - 60 секунд.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась без теста. Поэтому необхожимо было написать тест, прверяющий корректность работы программы. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *пару скунд*

Вот как я построил `feedback_loop`:
1. Написал performance тест для защиты от деградации производительности
2. Написал тест для проверки корректности работы программы
2. Написал програмки для запуска различных профилировщиков.
3. Подключил Guard чтобы не тратить время на ручной запуск тестов

Сам `feedback_loop`:
1. запуск профилировщиков и выявление наиболее жирных мест.
1.1. Рефакторинг, если плохо понятно в каком именно месте программы узкое место
1.2. Запуск тестов
1.2. Goto 1
2. Внесение необходимых изменений
3. Запуск тестов
3.1. Откат изменений если тесты не прошли
4. Если метрика не соответствует бюджету - Goto 1

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался *ruby-prof, pg_hero, rack-mini-profiler*

Вот какие проблемы удалось найти и решить

### Находка №1
- Запуск профилировщика показал, что при импорте товаров наибольшее время занимает выполнение метода `PG::Connection#async_exec_params`. Для импорта одной строки файла, выполняется слишком много SQL запросов (минимум 6). Их количество можно уменьшить за счет мемоизации, а также подключения библиотеки `active-record-import`.
- Добавил мемоизацию и импорт трипов через ar-import.
- Метрика улучшилась в 2 раза для маленьких файлов и в 6 раз для большого.
- Отчет профилировщика показывает на `PG::Connection#async_exec_params`.

### Находка №2
- Главная точка роста - та же. Из-за постоянных апдейтов информации об автобусе на каждой строки фала.
- Изменил подход, теперь я сначала собирую информацию об автобусах и их услугах для импорта всего массива сразу, и только затем на втором прогоне собираю информацию о трипах.
- Метрика уложилась в бюджет. Прогон большого файла занимает около 40 секунд.

Переходим к профилированию страницы расписаний. Для этого я подключю bullet, rack-mini-profile, rails-panel

### Находка №3
- Подключил Bullet - он подсказвает, что на странице не хватает жадной загрузки автобусов, и рекомендует сделать ее через include
- Сделал по рекомендации, предупреждение ушло.

### Находка №4
- Посмотрел RackMiniProfiler - он утверждает что наибольшее время занимает рендер паршала услуги.
- Избавился от этого паршала, т.к. не очень ясно зачем нужно выносить единственную строку в паршал. А также убрал ненужную интерполяцию.
- Страница стала загружаться примерно в 4 раза быстрее (для small файла)

### Находка №5
- Установил PGHero. Странно, но на странице все было зелено. Никаких рекомендация по индексам нет... В нем же заметил два похожих запроса на получение записей + количества записей.
- Раз уж мы все равно грузим записи в память, то можно не запрашивать отдельно количество всех записей. Заменил count на size, и добавил явный load записей в контроллере, иначе запрос все равно бы шел.
- Время загрузки страницы не изменилось.

### Находка №6
- rack-mini-profiler показывает, что основное время уходит на рендер
- Поэтому я убрал все паршалы.
- Вся страница Самара/Москва грузится чуть меньше чем за 10 секунд (large.json)

### Находка №7
- Сделал Exmplain запроса получения трипов, план можно улучшить добавив индекс по from_id, to_id.
- Добавил индекс по этим полям, а также доваил индекс по полю bus_id в таблице buses_services.
- Запрос трипов стал выполняться почти втрое быстрее. Для таблицы buses_services также повысилась производительность запроса в 2,5 раза.
- На время загрузки страницы это практически не повлияло. Выиграли несколько милисекунд, но базе стало полегче. Остальные данные и так запрашиваются по первичному ключу.

### Результаты:

Попробовал такие новые инструменты как pghero, rack-mini-profile, rails-panel, bullet. Ранее с ними не работал. Они действительно могут помочь в оптимизации, и дать информацию в более удобном виде, нежели просто смотреть в логи.

Как мне кажется на странице не хватает частичной загрузки. В реальной жизни весь этот объем информации пользователю сразу просто не нужен. В задании не стояло какой-либо метрики, для страницы, к которой надо стремиться. Поэтому этого решил не делать.
