# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла проблема.

Необходимо было импортрировать данные из большого файла, затем отобразить данные в веб-интерфейсе.

Наша программа успешно работала на файлах небольшого размера, но для большого файла она работала слишком медленно.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такие метрики: 1) общее время выполнения импорта данных; 2) общее время рендеринга страницы.

## Гарантия корректности работы оптимизированной программы
Программа была без тестов.
Для гарантии корректности работы, до начала работы над оптимизацией я добавил тест на импортер данных и системный тест для проверки результата рендеринга страницы.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за короткое время.

Вот как я построил `feedback_loop`:

- Вынес код для импортера данных в отдельный класс, добавил бенчмарк.
- Добавил тесты.
- После внесенных изменений в код, делал следующее:
- 1) Проверял, что тест проходит.
- 2) Запускал бенчмарк.
- 3) Запускал интересующие меня профилировщики и изучал отчеты.

### Итерация 1:

По логам было видно, что импортер делает слишком много лишних SQL-запросов в базу.
Я переписал программу так, чтобы City, Bus, Service кэшировались в памяти.
Далее, когда я увидел в логах, что добился в этом успеха, и что посторяющиеся запросы касаются только создания записей Trip,
я добавил гем activerecord-import и сделал импорт Trip в одном батче.

После этого файл large.json, стал импортироваться за 40 сек, что укладывалось в бюджет, и перешел к оптимизации рендеринга страницы.

### Итерация 2:

Bullet сразу показал проблему с N+1 (отсутствие eager_load / preload / includes), я исправил это в первую очередь.
Далее по отчету rack-mini-profiler я увидел, какие у нас есть повторяющиеся / лишние запросы, и постарался избавиться от них.
Также rack-mini-profiler показал, что значительное количество времени тратится на рендеринг partial'ов, я попробовал вынести код из них в index.html и стало намного быстрее.

Как изменилась метрика:

Было: 30 сек (файл large.json)

Стало: 3.3 сек, из них SQL - 4.5%. Я посчитал, что это достаточно.

### Итерация 3:

В третьей итерации я вернулся к оптимизации импортера, чтобы выполнить бонусное задание.
Переписал код импортера таким образом, чтобы загружать данные в Postgres потоком.

Результаты:

1) large.json: время уменьшилось с 40 сек до 11 сек.

2) 1M.json: 80 сек.

3) 10M: 15 минут. Уверен, что можно оптимизировать далее.
