# Case-study оптимизации A

## Актуальная проблема
Нужно оптимизировать механизм перезагрузки расписания из файла так, чтобы он импортировал файл `large.json` **в пределах минуты**.

`rake reload_json[fixtures/large.json]`

Я решил исправить эту проблему, оптимизировав этот скрипт.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: время выполнения скрипта с момента запуска и до момента окончания.

## Гарантия корректности работы оптимизированной программы
Результат работы страницы `автобусы/Самара/Москва` для данных из файла `fixtures/example.json` не должен меняться от применения оптимизаций.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы, я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за меньшее полутора минут время.

Вот как я построил `feedback_loop`: мы уже имеем разбиение входных данных на разные объемы, поэтому остается построить тесты для фиксирования текущей производительности в процессе работы как отправной точки. Самая первая итерация представляла из себя написание тестов производительности (время выполнения программы). В данном случае это можно отнести к шагу Profile & Test & Benchmark. Полученные при первом запуске значения бенчмарка мы можем записать в цели теста для исключения регрессий на последующих итерациях.
С этого момента наш feedback loop создан, и мы можем переходить к профилированию и изменению кода, после чего запускать уже написанные тесты для сравнения результатов с отправным шагом (или шагом предыдущей итерации).

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался инструментами memory-profiler и ruby-prof.

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- какой отчёт показал главную точку роста
  * ruby-prof с профилем на small.json указал на большее время, проведенное внутри ActiveRecord::Persistence#update (`bus.update`: 4.5 сек и 1000 вызовов), ActiveRecord::Querying#find_or_create_by (3.67 сек и 7229 вызовов) и ActiveRecord::Persistence::ClassMethods#create! (1.11 сек и 1000 вызовов). Это и есть наша первая точка роста.
- как вы решили её оптимизировать
  * на этом этапе оптимизации импорта данных были удалены избыточные шаги поиска, создания и обновления записей в БД. Попутно была создана недостающая модель BusesService в БД, на которую уже была ссылка в качестве общей таблицы внутри Bus и Service моделей. Для массовой вставки записей в БД был использован gem 'activerecord-import'. Для более новых версий Rails можно было бы обойтись insert_all. Исходя из знаний об ожидаемых данных было возможно применить запись данных в базу "кусками". Для этого мы считываем определенное число строк, обрабатываем их и сразу же сохраняем записи о поездках. Затем переходим к следующему блоку данных и т.д. Весь блок обработки данных был вынесен в отдельный класс. Ключевым в снижении числа обращений к базе внутри транзакции стало использование хэшей для хранения созданных новых записей. В первую очередь происходит поиск и использование значений из хэшей и только потом происходит поиск или создание новой записи в базе.
- как изменилась метрика
  * время выполнения импорта малого объема данных снизилось до 2.2 секунд с 3.5 секунд, а для среднего объема данных с 65 секунд до 5.1 секунд. Большой объем данных импортируется за 17.6 секунд.
- как изменился отчёт профилировщика
  * согласно профилировщику основное время после оптимизации теперь стало уходить на ActiveRecord::Querying#find_or_create_by (6.88 секунды и 3255 вызова).

## Результаты
В результате проделанной оптимизации наконец удалось обработать большой файл с данными за целевое время.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях скрипта тесты на производительность алгоритма были зафиксированы на новых значениях, достигнутых за счет оптимизации.
