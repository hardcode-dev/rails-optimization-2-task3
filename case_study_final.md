# Case-study оптимизации

## Актуальная проблема
В полученном задании поставлена задача загрузить за 1 минуту large файл c данными
и максимально оптимизировать работу приложения.

## Бюджет

Необходимо уложиться в две метрики:
1) Время импорта fixtures/large.json файла должно быть менее минуты.
2) Время рендеринга страницы с расписание должно укладываться в 500 МС.

## Гарантия работы

В самом начале работы на импорт был написан тест, который защищает нас от логически
неправильных действий. В процессе работы тест так же подвергался изменениям вслед за
структурой базы.

## Feedback-Loop

1) Для проверки скорости иморта был использован Benchmark
2) Для проверки скорости работы web части приложения был использован rack-mini-profiler

## Работа над импортом

### Старт работ

В начале работы импорт medium файла занимает 96 секунд. Это долго.

### Моя находка №1

Очевидно, что создавать Trip по одному слишком долго. Так же постараемся внедрить
ARImport для всего, чего только можно. Начнем с самой большой модели Trip.
Будем накапливать пачки с скидывать пачки в постгрес. По экспериментам быстрее всего работает
при размере пачки в 100 штук.

medium за 75

### Моя находка №2
Нашел баг при штатном импорте.
Если считать, что для bus первичным является пара number + model, то нужно в дефолтном импорте поправить импорт bus.
При этом знаем, что сервисов строго конечное кол-во. Импортируем их все сразу и
кешируем в инстансную переменную. Привязку сервисов к bus тоже делаем через ARImport

medium за 41

### Моя находка №3
Так как впереди планируется импорт больших файлов, то перевел на поточный парсинг.
ruby-prof теперь четко показывает, что парсинг json ест много, но и видны остальные точки.

medium за 60, деградация

### Моя находка №4

BusesServices перевел на ARImport.
medium за 30 секунд

### Моя находка №5
Перевел id в City на uuid, чтобы генерить на лету. Теперь можно так же
импортировать через import.
medium за 17

### Моя находка №6
Перевел id в Bus на uuid, чтобы генерить на лету. Теперь можно так же
импортировать через import.
medium за 7.6
large за 70.6 Пока буду считать, что укладываюсь.

### Моя находка №7 ( уже в процессе работы над web )
Проверил исходный файл. Оказывается, что сервисы в автобусе не зависят от маршрута.
Тогда можно денормализовать таблицы и положить сервисы прямо в автобусы.

Теперь импорт large в 46 секунд

## Работа над web-интерфейсом

### Моя находка №1
Из логов нашел, что при рендеринге постоянно стреляет n+1 в виде запроса
SELECT  "buses".* FROM "buses" WHERE "buses"."id" = $1 LIMIT $2
Сделаем includes(:bus) в контроллере

### Моя находка №2
Из логов нашел, что при рендеринге постоянно стреляет n+1 в виде запроса
SELECT "services".* FROM "services"
INNER JOIN "buses_services" ON "services"."id" = "buses_services"."service_id"
WHERE "buses_services"."bus_id" = $1
Сделаем includes(bus: :services) в контроллере

### Моя находка №3
Пытался использовать rails-panel. Не работает нормально в хроме. Один запрос
отслеживает и падает на втором. Использую rack-mini-profiler

Перешел на rack-mini-profiler. Он показывает, что страница грузится 23 секунды.
Закешировал партиалы для сервисов автобуса. Время сократилось до 14 секунд.

### Моя находка №4
rack-mini-profiler
Убрал много лишнего рендеринга партиала service. 7 секунд.

### Моя находка №5
rack-mini-profiler
Убрал много лишнего рендеринга партиала delimiter. 4 секунды.

### Моя находка №6
rack-mini-profiler
Все запросы выполняются достаточно быстро и навешивание индексов не дает почти накаого
прироста.
Все время уходит на рендеринг и зависит от кол-ва объектов на странице.
Добавил пагинацию, теперь одна страничка грузится в пределах 200 мс.

## Результаты

В результате оптимизации уложились в оба бюджета, как по импорту, так и по отображению.

## Защита

Тесты функциональные приведены в порядок после изменения структуры данных.
Так же добавлены тесты на производительность импорта.

Тест на импорт сделан с небольшим запасом до 0,1 секунды на example.
